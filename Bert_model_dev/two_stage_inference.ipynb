{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d28a28f-668f-48cf-b07a-c53b31d9651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4590ef07-90ce-4fa0-931f-be4dc7d1f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/nfs/turbo/med-kayvan-lab/Projects/ARDS/Code/Yufeng/CXR/NLP/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a4b62b-ce5f-4106-82b5-d1e43f200421",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_output_path = os.path.join(model_path,'task1/bert-base-uncased/dataset_combined_enhanced_epoch_5_learning_rate_1e-05_regu_0.01/output.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98bf4e59-e412-42d5-a7e1-e8249ca8f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_output_path = os.path.join(model_path,'task2/bert-base-uncased/dataset_combined_enhanced_epoch_20_learning_rate_1e-06_regu_0.01/output.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85333d43-35ee-44d3-9f9c-ed9c530e3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/nfs/turbo/med-kayvan-lab/Projects/ARDS/Code/Yufeng/CXR/NLP/outputs/stage1_stage2/output.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7e81bb67-afcf-4882-95c9-c31f1e0c4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First stage --\n",
      "    \t Accuracy is 0.556;\n",
      "    \t Specificity is 0.000; Precision is 0.556; Recall is 1.000; F1 is 0.714.\n",
      " Second stage -- macro\n",
      "    \t Accuracy is 0.479;\n",
      "    \t Specificity is 0.555; Precision is 0.298; Recall is 0.555; F1 is 0.356.\n",
      " Second stage -- micro\n",
      "    \t Accuracy is 0.479;\n",
      "    \t Specificity is 0.479; Precision is 0.479; Recall is 0.479; F1 is 0.479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloezh/miniconda3/envs/torchsrh/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chloezh/miniconda3/envs/torchsrh/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "output_path_UW = '/nfs/turbo/med-kayvan-lab/Projects/ARDS/Code/Yufeng/CXR/NLP/outputs/stage1_stage2_UW/output.pkl'\n",
    "with open(output_path_UW, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "    gold_binary = loaded_data['gold_binary']\n",
    "    task1_preds = loaded_data['task1_preds']\n",
    "    gold_sentence = loaded_data['gold_sentence']\n",
    "    task2_preds = loaded_data['task2_preds']\n",
    "gold_sentence = np.array([int(value) for array in gold_sentence for value in array])\n",
    "task1_preds = np.array([int(value) for array in task1_preds for value in array])\n",
    "task2_preds = np.array([int(value) for array in task2_preds for value in array])\n",
    "gold_binary = np.array(gold_binary)\n",
    "gold_sentence = np.array(gold_sentence)\n",
    "task2_preds_pro = task2_preds[task1_preds == 1]\n",
    "gold_sentence_pro = gold_sentence[task1_preds == 1]\n",
    "[test_acc,test_precision,test_recall,test_specificity,test_f1] = metrics_calucation(gold_binary,task1_preds)\n",
    "print(f''' First stage --\n",
    "    \\t Accuracy is {test_acc:.3f};\n",
    "    \\t Specificity is {test_specificity:.3f}; Precision is {test_precision:.3f}; Recall is {test_recall:.3f}; F1 is {test_f1:.3f}.''')\n",
    "\n",
    "[test_acc,test_precision,test_recall,test_specificity,test_f1] = metrics_calucation(gold_sentence_pro,task2_preds_pro,multi = 'macro')\n",
    "print(f''' Second stage -- macro\n",
    "    \\t Accuracy is {test_acc:.3f};\n",
    "    \\t Specificity is {test_specificity:.3f}; Precision is {test_precision:.3f}; Recall is {test_recall:.3f}; F1 is {test_f1:.3f}.''')\n",
    "[test_acc,test_precision,test_recall,test_specificity,test_f1] = metrics_calucation(gold_sentence_pro,task2_preds_pro,multi = 'micro')\n",
    "print(f''' Second stage -- micro\n",
    "    \\t Accuracy is {test_acc:.3f};\n",
    "    \\t Specificity is {test_specificity:.3f}; Precision is {test_precision:.3f}; Recall is {test_recall:.3f}; F1 is {test_f1:.3f}.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "04f1d194-0ff5-47fa-9865-6c9dcea30488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "    gold_binary = loaded_data['gold_binary']\n",
    "    task1_preds = loaded_data['task1_preds']\n",
    "    gold_sentence = loaded_data['gold_sentence']\n",
    "    task2_preds = loaded_data['task2_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08cc52d4-5d1a-469e-8691-353e7f716bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(task2_output_path, 'rb') as file:\n",
    "#     loaded_data = pickle.load(file)\n",
    "#     gold_sentence = loaded_data['gold_sentence']\n",
    "#     task2_preds = loaded_data['task2_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06bc1a53-0419-4bac-b0d6-63932e8d44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_binary = np.array([int(value) for array in gold_binary for value in array])\n",
    "gold_sentence = np.array([int(value) for array in gold_sentence for value in array])\n",
    "task1_preds = np.array([int(value) for array in task1_preds for value in array])\n",
    "task2_preds = np.array([int(value) for array in task2_preds for value in array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6e5f5b8-2696-4095-9100-2115133a2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_binary = np.array(gold_binary)\n",
    "gold_sentence = np.array(gold_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9d2f67f-8ae2-4a03-ba58-2062aabc129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint2 = '/nfs/turbo/med-kayvan-lab/Projects/ARDS/Code/Yufeng/CXR/NLP/models/task2/bert-base-uncased/dataset_combined_enhanced_epoch_20_learning_rate_1e-06_regu_0.01/model.pth'\n",
    "# state_dict = torch.load(checkpoint2, map_location='cpu')\n",
    "# print(\"Layer names and their parameter shapes:\")\n",
    "# for key in state_dict:\n",
    "#     print(f\"{key}: {state_dict[key].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8bdbcf6e-fc82-451d-ad8b-8c4cca0079de",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_preds_pro = task2_preds[task1_preds == 1]\n",
    "gold_sentence_pro = gold_sentence[task1_preds == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cae705e-0fcb-4e07-9d5b-c4f460c4e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b1081d3-879e-48dd-a7be-62d9a11bb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calucation(labels,predictions,multi = 'binary'):\n",
    "    recall = recall_score(labels, predictions,average=multi)\n",
    "    precision = precision_score(labels, predictions,zero_division=0,average=multi)\n",
    "    specificity = recall_score(1-labels, 1-predictions,average=multi)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions,average=multi)\n",
    "\n",
    "    return [accuracy,precision,recall,specificity,f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0bde8e8f-2959-462b-8561-0e3e2eb5f69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First stage --\n",
      "    \t Accuracy is 0.537;\n",
      "    \t Specificity is 0.059; Precision is 0.550; Recall is 0.918; F1 is 0.688.\n"
     ]
    }
   ],
   "source": [
    "[test_acc,test_precision,test_recall,test_specificity,test_f1] = metrics_calucation(gold_binary,task1_preds)\n",
    "print(f''' First stage --\n",
    "    \\t Accuracy is {test_acc:.3f};\n",
    "    \\t Specificity is {test_specificity:.3f}; Precision is {test_precision:.3f}; Recall is {test_recall:.3f}; F1 is {test_f1:.3f}.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27d3f3e7-90d4-4acf-bb94-b27a1f705bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Second stage -- macro\n",
      "    \t Accuracy is 0.488;\n",
      "    \t Specificity is 0.620; Precision is 0.325; Recall is 0.620; F1 is 0.412.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chloezh/miniconda3/envs/torchsrh/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/chloezh/miniconda3/envs/torchsrh/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "[test_acc,test_precision,test_recall,test_specificity,test_f1] = metrics_calucation(gold_sentence_pro,task2_preds_pro,multi = 'macro')\n",
    "print(f''' Second stage -- macro\n",
    "    \\t Accuracy is {test_acc:.3f};\n",
    "    \\t Specificity is {test_specificity:.3f}; Precision is {test_precision:.3f}; Recall is {test_recall:.3f}; F1 is {test_f1:.3f}.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69fe685f-153e-4d40-9be2-339ce1bd3cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Second stage -- micro\n",
      "    \t Accuracy is 0.488;\n",
      "    \t Specificity is 0.488; Precision is 0.488; Recall is 0.488; F1 is 0.488.\n"
     ]
    }
   ],
   "source": [
    "[test_acc,test_precision,test_recall,test_specificity,test_f1] = metrics_calucation(gold_sentence_pro,task2_preds_pro,multi = 'micro')\n",
    "print(f''' Second stage -- micro\n",
    "    \\t Accuracy is {test_acc:.3f};\n",
    "    \\t Specificity is {test_specificity:.3f}; Precision is {test_precision:.3f}; Recall is {test_recall:.3f}; F1 is {test_f1:.3f}.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchsrh",
   "language": "python",
   "name": "torchsrh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
